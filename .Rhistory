sei = sei,
vi = sei^2,
pval = 2 * ( 1 - pnorm( abs(yi) / sei ) ) )
# 1-tailed publication bias
signif = d$pval < 0.05 & d$yi > 0
publish = rep( 1, nrow(d) )
publish[ signif == FALSE ] = rbinom( n = sum(signif == FALSE), size = 1, prob = 1/p$eta )
d$weight = 1
d$weight[ signif == 0 ] = p$eta
d = d[ publish == 1, ]
return(d)
}
# ##### Sanity Check #####
# d = sim_data( data.frame( k = 5,
#                           per.cluster = 20,
#                           mu = .5,
#                           V = 1,
#                           V.gam = .5,
#                           sei.min = 0.01,
#                           sei.max = 0.01,
#                           eta = 1 ) )
# does corrected_meta agree with regular meta-analysis fns when there
#  is no selection?
test_that("corrected_meta #1", {
##### Recover Regular FE model With Eta = 1 #####
# when using z-based inference and eta = 1,
# should match metafor
dat = escalc(measure="RR", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg)
FE.plain = rma( yi, vi, data = dat, method = "FE" )
# should match corrected with eta = 1
FE.adj = corrected_meta( yi = dat$yi,
vi = dat$vi,
eta = 1,
model = "fixed",
selection.tails = 1,
CI.level = 0.95,
small = FALSE,
favor.positive = FALSE )
expect_equal( FE.adj$est, as.numeric(FE.plain$b), tol = 0.001 )
expect_equal( FE.adj$se, as.numeric(FE.plain$se), tol = 0.001 )
expect_equal( FE.adj$lo, as.numeric(FE.plain$ci.lb), tol = 0.001 )
expect_equal( FE.adj$hi, as.numeric(FE.plain$ci.ub), tol = 0.001 )
expect_equal( FE.adj$pval, as.numeric(FE.plain$pval), tol = 0.001 )
##### Recover Regular Robust Indepenent Model With Eta = 1 #####
for ( .small in c(TRUE, FALSE) ) {
clustervar = 1:length(dat$yi)
meta.re = rma.uni( yi = dat$yi,
vi = dat$vi)
t2hat.naive = meta.re$tau2
RI.robust = robu( yi ~ 1,
studynum = clustervar,
data = dat,
userweights = 1 / (vi + t2hat.naive),
var.eff.size = vi,
small = .small )
RI.adj = corrected_meta( yi = dat$yi,
vi = dat$vi,
eta = 1,
model = "robust",
selection.tails = 1,
CI.level = 0.95,
small = .small,
favor.positive = FALSE)
expect_equal( RI.adj$est, as.numeric( as.numeric(RI.robust$b.r) ), tol = 0.001 )
expect_equal( RI.adj$se, as.numeric( RI.robust$reg_table$SE ), tol = 0.001 )
expect_equal( RI.adj$lo, as.numeric( RI.robust$reg_table$CI.L ), tol = 0.001 )
expect_equal( RI.adj$hi, as.numeric( RI.robust$reg_table$CI.U ), tol = 0.001 )
expect_equal( RI.adj$pval, as.numeric( RI.robust$reg_table$prob ), tol = 0.001 )
}
##### Recover Regular Robust Clustered Model With Eta = 1 #####
for ( .small in c(TRUE, FALSE) ) {
clustervar = dat$author
meta.re = rma.uni( yi = dat$yi,
vi = dat$vi)
t2hat.naive = meta.re$tau2
RI.robust = robu( yi ~ 1,
studynum = clustervar,
data = dat,
userweights = 1 / (vi + t2hat.naive),
var.eff.size = vi,
small = .small )
RI.adj = corrected_meta( yi = dat$yi,
vi = dat$vi,
eta = 1,
model = "robust",
clustervar = clustervar,
selection.tails = 1,
CI.level = 0.95,
small = .small,
favor.positive = FALSE)
expect_equal( RI.adj$est, as.numeric( as.numeric(RI.robust$b.r) ), tol = 0.001 )
expect_equal( RI.adj$se, as.numeric( RI.robust$reg_table$SE ), tol = 0.001 )
expect_equal( RI.adj$lo, as.numeric( RI.robust$reg_table$CI.L ), tol = 0.001 )
expect_equal( RI.adj$hi, as.numeric( RI.robust$reg_table$CI.U ), tol = 0.001 )
expect_equal( RI.adj$pval, as.numeric( RI.robust$reg_table$prob ), tol = 0.001 )
}
})
# do svalue and corrected_meta agree?
test_that("svalue #1", {
dat = escalc(measure="RR", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg)
for ( .CI.level in c(.8, .95) ) {
for ( .small in c(TRUE, FALSE) ) {
svals = svalue( yi = dat$yi,
vi = dat$vi,
q = 0,
model = "fixed",
CI.level = 0.95,
small = .small,
favor.positive = FALSE )$svals
# CI upper limit should be exactly 0 when eta = sval.ci
meta = corrected_meta( yi = dat$yi,
vi = dat$vi,
eta = as.numeric(svals["sval.ci"]),
model = "fixed",
selection.tails = 1,
CI.level = 0.95,
small = .small,
favor.positive = FALSE )
expect_equal( meta$hi, 0 )
}
}
} )
dat = escalc(measure="RR", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg)
.CI.level = .8
.small=TRUE
svals = svalue( yi = dat$yi,
vi = dat$vi,
q = 0,
model = "fixed",
CI.level = 0.95,
small = .small,
favor.positive = FALSE )$svals
svals
svals = svalue( yi = dat$yi,
vi = dat$vi,
q = 0,
model = "fixed",
CI.level = 0.95,
small = .small,
favor.positive = FALSE )
svals
test_that("svalue #1", {
dat = escalc(measure="RR", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg)
for ( .CI.level in c(.8, .95) ) {
for ( .small in c(TRUE, FALSE) ) {
svals = svalue( yi = dat$yi,
vi = dat$vi,
q = 0,
model = "fixed",
CI.level = 0.95,
small = .small,
favor.positive = FALSE )
# CI upper limit should be exactly 0 when eta = sval.ci
meta = corrected_meta( yi = dat$yi,
vi = dat$vi,
eta = as.numeric(svals$sval.ci),
model = "fixed",
selection.tails = 1,
CI.level = 0.95,
small = .small,
favor.positive = FALSE )
expect_equal( meta$hi, 0 )
}
}
} )
# does it reject bad choices of q?
test_that( "svalue #3", {
dat = escalc(measure="RR", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg)
expect_error( svalue( yi = dat$yi,
vi = dat$vi,
q = -3,
model = "fixed",
CI.level = 0.95,
small = FALSE,
favor.positive = FALSE) )
# reverse signs
expect_error( svalue( yi = -dat$yi,
vi = dat$vi,
q = .8,
model = "fixed",
CI.level = 0.95,
small = FALSE,
favor.positive = FALSE) )
} )
# does svalue give correct results when the s-value is greater than the highest
#  value in eta grid?
test_that( "svalue #4", {
eta = 3
d = sim_data( data.frame( k = 50,
per.cluster = 5,
mu = 0.5,
V = 0,
V.gam = 0,
sei.min = 0.1,
sei.max = 1,
eta = eta ) )
svals = svalue( yi = d$yi,
vi = d$vi,
q = 0,
model = "robust",
eta.grid = seq(1,10,1),
CI.level = 0.95,
small = FALSE,
favor.positive = FALSE)
} )
eta = 3
d = sim_data( data.frame( k = 50,
per.cluster = 5,
mu = 0.5,
V = 0,
V.gam = 0,
sei.min = 0.1,
sei.max = 1,
eta = eta ) )
svals = svalue( yi = d$yi,
vi = d$vi,
q = 0,
model = "robust",
eta.grid = seq(1,10,1),
CI.level = 0.95,
small = FALSE,
favor.positive = FALSE)
svals
eta = 50
d = sim_data( data.frame( k = 50,
per.cluster = 1,
mu = 0.5,
V = 0.1,
V.gam = 0,
# sei.min = 0.2,
# sei.max = .9,
sei.min = .1,
sei.max=.1,
eta = eta ) )
# also see if significance_funnel works
expect_error( significance_funnel( yi = d$yi,
vi = d$vi ) )
significance_funnel( yi = d$yi,
vi = d$vi )
significance_funnel( yi = d$yi,
vi = d$vi,
favor.positive = FALSE)
# does significance_funnel give error if no non-affirmative studies?
test_that( "significance_funnel #1", {
eta = 50
d = sim_data( data.frame( k = 50,
per.cluster = 1,
mu = 0.5,
V = 0.1,
V.gam = 0,
# sei.min = 0.2,
# sei.max = .9,
sei.min = .1,
sei.max=.1,
eta = eta ) )
# also see if significance_funnel works
expect_error( significance_funnel( yi = d$yi,
vi = d$vi,
favor.positive = FALSE) )
} )
dat = escalc(measure="RR", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg)
expect_error( svalue( yi = dat$yi,
vi = dat$vi,
q = -3,
model = "fixed",
CI.level = 0.95,
small = FALSE,
favor.positive = FALSE) )
svalue( yi = dat$yi,
vi = dat$vi,
q = -3,
model = "fixed",
CI.level = 0.95,
small = FALSE,
favor.positive = FALSE)
dat = escalc(measure="RR", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg)
debug(svalue)
svalue( yi = dat$yi,
vi = dat$vi,
q = -3,
model = "fixed",
CI.level = 0.95,
small = FALSE,
favor.positive = FALSE)
m0
svalue( yi = dat$yi,
vi = dat$vi,
q = 0,
model = "fixed",
CI.level = 0.95,
small = FALSE,
favor.positive = FALSE)
favor.positive = FALSE)
m0
svalue( yi = dat$yi,
vi = dat$vi,
q = -0.4,  # closer to null than naive estimate, but within CI
model = "fixed",
CI.level = 0.95,
small = FALSE,
favor.positive = FALSE)
q
sval.est
sval.ci
sval.ci
sval.ci
svalue( yi = dat$yi,
vi = dat$vi,
q = -0.4,  # closer to null than naive estimate, but within CI
model = "robust",
CI.level = 0.95,
small = FALSE,
favor.positive = FALSE)
m0
svalue( yi = dat$yi,
vi = dat$vi,
q = -0.6,  # closer to null than naive estimate, but within CI
model = "robust",
CI.level = 0.95,
small = FALSE,
favor.positive = FALSE)
m0$lo
source('~/Dropbox/Personal computer/Independent studies/Sensitivity analysis for publication bias (SAPB)/Linked to OSF (SAPB)/R package PublicationBias/PublicationBias/R/functions.R')
svalue( yi = dat$yi,
vi = dat$vi,
q = -0.6,  # closer to null than naive estimate, but within CI
model = "robust",
CI.level = 0.95,
small = FALSE,
favor.positive = FALSE)
svalue( yi = dat$yi,
vi = dat$vi,
q = -0.4,  # closer to null than naive estimate, but within CI
model = "fixed",
CI.level = 0.95,
small = FALSE,
favor.positive = FALSE)
# bm
svalue( yi = dat$yi,
vi = dat$vi,
q = -0.4,  # closer to null than naive estimate, but within CI
model = "fixed",
CI.level = 0.95,
small = FALSE,
favor.positive = FALSE)
debug(svalue)
svalue( yi = dat$yi,
vi = dat$vi,
q = -0.4,  # closer to null than naive estimate, but within CI (from being in browser and looking at m0)
model = "fixed",
CI.level = 0.95,
small = FALSE,
favor.positive = FALSE)
m0
svalue( yi = dat$yi,
vi = dat$vi,
q = -0.6,  # closer to null than naive estimate, but within CI
model = "robust",
CI.level = 0.95,
small = FALSE,
favor.positive = FALSE)
m0
undebug(svalue)
# naive: -0.7145323 [-1.104935, -0.3241296]
svalue( yi = dat$yi,
vi = dat$vi,
q = -0.6,  # closer to null than naive estimate, but within CI
model = "robust",
CI.level = 0.95,
small = FALSE,
favor.positive = FALSE)
# bm
# naive: -0.4302852 [-0.5096613, -0.3509091]
expect_message( svalue( yi = dat$yi,
vi = dat$vi,
q = -0.4,  # closer to null than naive estimate, but within CI (from being in browser and looking at m0)
model = "fixed",
CI.level = 0.95,
small = FALSE,
favor.positive = FALSE) )
# should run without message/error
svalue( yi = dat$yi,
vi = dat$vi,
q = -0.3,  # closer to null than naive estimate, but within CI (from being in browser and looking at m0)
model = "fixed",
CI.level = 0.95,
small = FALSE,
favor.positive = FALSE)
# naive: 0.7145323 [0.3241296, 1.104935]
svalue( yi = -dat$yi,
vi = dat$vi,
q = 0.6,  # closer to null than naive estimate, but within CI
model = "robust",
CI.level = 0.95,
small = FALSE,
favor.positive = TRUE)
debug(svalue)
svalue( yi = -dat$yi,
vi = dat$vi,
q = 0.6,  # closer to null than naive estimate, but within CI
model = "robust",
CI.level = 0.95,
small = FALSE,
favor.positive = TRUE)
m0
q
m0$est
m0$lo
source('~/Dropbox/Personal computer/Independent studies/Sensitivity analysis for publication bias (SAPB)/Linked to OSF (SAPB)/R package PublicationBias/PublicationBias/R/functions.R')
svalue( yi = -dat$yi,
vi = dat$vi,
q = 0.6,  # closer to null than naive estimate, but within CI
model = "robust",
CI.level = 0.95,
small = FALSE,
favor.positive = TRUE)
# should run without message or error
expect_message( svalue( yi = -dat$yi,
vi = dat$vi,
q = 0.3,  # closer to null than naive estimate, but within CI
model = "robust",
CI.level = 0.95,
small = FALSE,
favor.positive = TRUE) )
svalue( yi = -dat$yi,
vi = dat$vi,
q = 0.3,  # closer to null than naive estimate, but within CI
model = "robust",
CI.level = 0.95,
small = FALSE,
favor.positive = TRUE)
test_that("svalue #3.5", {
dat = escalc(measure="RR", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg)
# fixed case
# naive: -0.4302852 [-0.5096613, -0.3509091]
# should give message about sval.ci not applying
expect_message( svalue( yi = dat$yi,
vi = dat$vi,
q = -0.4,  # closer to null than naive estimate, but within CI (from being in browser and looking at m0)
model = "fixed",
CI.level = 0.95,
small = FALSE,
favor.positive = FALSE) )
# should run without message/error
svalue( yi = dat$yi,
vi = dat$vi,
q = -0.3,  # closer to null than naive estimate, but within CI (from being in browser and looking at m0)
model = "fixed",
CI.level = 0.95,
small = FALSE,
favor.positive = FALSE)
# robust case and flipped signs
# naive: 0.7145323 [0.3241296, 1.104935]
expect_message( svalue( yi = -dat$yi,
vi = dat$vi,
q = 0.6,  # closer to null than naive estimate, but within CI
model = "robust",
CI.level = 0.95,
small = FALSE,
favor.positive = TRUE) )
# should run without message or error
svalue( yi = -dat$yi,
vi = dat$vi,
q = 0.3,  # closer to null than naive estimate, but within CI
model = "robust",
CI.level = 0.95,
small = FALSE,
favor.positive = TRUE)
stop()
})
# does it produce appropriate warnings when q is already inside the CI?
test_that("svalue #3.5", {
dat = escalc(measure="RR", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg)
# fixed case
# naive: -0.4302852 [-0.5096613, -0.3509091]
# should give message about sval.ci not applying
expect_message( svalue( yi = dat$yi,
vi = dat$vi,
q = -0.4,  # closer to null than naive estimate, but within CI (from being in browser and looking at m0)
model = "fixed",
CI.level = 0.95,
small = FALSE,
favor.positive = FALSE) )
# should run without message/error
svalue( yi = dat$yi,
vi = dat$vi,
q = -0.3,  # closer to null than naive estimate, but within CI (from being in browser and looking at m0)
model = "fixed",
CI.level = 0.95,
small = FALSE,
favor.positive = FALSE)
# robust case and flipped signs
# naive: 0.7145323 [0.3241296, 1.104935]
expect_message( svalue( yi = -dat$yi,
vi = dat$vi,
q = 0.6,  # closer to null than naive estimate, but within CI
model = "robust",
CI.level = 0.95,
small = FALSE,
favor.positive = TRUE) )
# should run without message or error
svalue( yi = -dat$yi,
vi = dat$vi,
q = 0.3,  # closer to null than naive estimate, but within CI
model = "robust",
CI.level = 0.95,
small = FALSE,
favor.positive = TRUE)
})
check()
build()
57/188
