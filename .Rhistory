#  AND we're still not very close to the target q,
#  that means the optimal value was above eta.grid.hi
if ( abs(sval.est - eta.grid.hi) < 0.0001 & diff > 0.0001 ) sval.est = paste(">", eta.grid.hi)
}
# do something similar for CI
if ( lo.worst > q ) {
sval.ci = "Not possible"
} else {
# define the function we need to minimize
# i.e., distance between corrected estimate and the target value of q
func = function(.eta) {
lo.corr = corrected_meta( yi = yi,
vi = vi,
eta = .eta,
model = model,
clustervar = clustervar,
selection.tails = 1,
favor.positive = favor.positive,
CI.level = CI.level,
small = small )$lo
return( abs(lo.corr - q))
}
opt = optimize( f = func,
interval = c(1, eta.grid.hi),
maximum = FALSE )
sval.ci = opt$minimum
# discrepancy between the corrected estimate and the s-value
diff = opt$objective
# if the optimal value is very close to the upper range of grid search
#  AND we're still not very close to the target q,
#  that means the optimal value was above eta.grid.hi
if ( abs(sval.ci - eta.grid.hi) < 0.0001 & diff > 0.0001 ) sval.ci = paste(">", eta.grid.hi)
}
# ##### Worst-case bound #####
# # as eta -> infinity
# # not supposed to use KNHA for FE model
#
# # flip signs back to original direction if needed
# if ( flipped == TRUE ) {
#   yi = -yi
# }
#
# meta.bd = corrected_meta( yi = yi[ A == 0 ],
#                 vi = vi[ A == 0 ],
#                 eta = 1,
#                 model = model,
#                 CI.level = CI.level,
#                 small = small )
}
# s-values less than 1 indicate complete robustness
# is.numeric is in case we have a "< XXX" string instead of a number
if ( is.numeric(sval.est) & !is.na(sval.est) & sval.est < 1) sval.est = "Not possible"
if ( is.numeric(sval.ci) & !is.na(sval.ci) & sval.ci < 1) sval.ci = "Not possible"
return( data.frame( sval.est,
sval.ci = sval.ci,
k.affirmative,
k.nonaffirmative,
signs.recoded = flipped ) )
}
svalue( yi = dat$yi,
vi = dat$vi,
q = 0,
favor.positive = FALSE,
model = "robust" )
debug(svalue)
svalue( yi = dat$yi,
vi = dat$vi,
q = 0,
favor.positive = FALSE,
model = "robust" )
table(yi>0)
svalue( yi = dat$yi,
vi = dat$vi,
q = 0,
favor.positive = FALSE,
model = "robust" )
q
table(A)
favor.positive
optimize( f = func,
interval = c(1, eta.grid.hi),
maximum = FALSE )
table(yi/sqrt(vi)>0)
source('~/Dropbox/Personal computer/Independent studies/Sensitivity analysis for publication bias (SAPB)/Linked to OSF (SAPB)/R package PublicationBias/PublicationBias/R/functions.R')
svalue = function( yi,
vi,
q,
clustervar = 1:length(yi),
model,
alpha.select = 0.05,
eta.grid.hi = 200,
favor.positive,
CI.level = 0.95,
small = TRUE ) {
# # # ~~~ TEST ONLY
# # require(metafor)
# # dat = metafor::escalc(measure="RR", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg)
# dat = sim_data( data.frame( k = 50,
#                             per.cluster = 5,
#                             mu = -0.5,
#                             V = 0.25,
#                             V.gam = 0,
#                             sei.min = 0.1,
#                             sei.max = 1,
#                             eta = 2 ) )
# yi = dat$yi
# vi = dat$vi
# q = -.1
# clustervar = 1:length(yi)
# CI.level = 0.95
# small = TRUE
# model = "robust"
# # # ~~ end test
# stop if eta doesn't make sense
if ( eta.grid.hi < 1 ) stop( "eta.grid.hi must be at least 1.")
# number of point estimates
k.studies = length(yi)
alpha = 1 - CI.level
# warn if clusters but user said fixed
nclusters = length( unique( clustervar ) )
if ( nclusters < k.studies & model == "fixed" ) {
warning( "You indicated there are clusters, but these will be ignored due to fixed-effects specification. To accommodate clusters, instead choose model = robust.")
}
# fit uncorrected model
m0 = corrected_meta( yi = yi,
vi = vi,
eta = 1,
model = model,
clustervar = clustervar,
selection.tails = 1,
favor.positive = favor.positive,
CI.level = CI.level,
small = small )
# stop if q is on wrong side of null
if ( m0$est > 0 & q > m0$est ) stop( paste( "The uncorrected pooled point estimate is ", round2(m0$est),
". q must be less than this value (i.e., closer to zero).",
sep = "" ) )
if ( m0$est < 0 & q < m0$est ) stop( paste( "The uncorrected pooled point estimate is ", round2(m0$est),
". q must be greater than this value (i.e., closer to zero).",
sep = "" ) )
# # reverse signs if needed to have pooled point estimate > 0
# if ( m0$est < 0 ) {
#   # keep track so that we can flip back at the end
#   flipped = TRUE
#   yi = -yi
#   q = -q
# } else {
#   flipped = FALSE
# }
##### Flip Estimate Signs If Needed #####
# if favor.positive == TRUE, then we don't need to fit a naive meta-analysis or do anything
if ( favor.positive == TRUE ) {
# keep track of whether we flipped for reporting at the end
flipped = FALSE
} else {
flipped = TRUE
yi = -yi
q = -q
}
# 2-sided p-values for each study even if 1-tailed selection
pvals = 2 * ( 1 - pnorm( abs(yi) / sqrt(vi) ) )
# affirmative indicator under 1-tailed selection
A = (pvals < alpha.select) & (yi > 0)
k.affirmative = sum(A)
k.nonaffirmative = k.studies - sum(A)
if ( k.affirmative == 0 | k.nonaffirmative == 0 ) {
stop( "There are zero affirmative studies or zero nonaffirmative studies. Model estimation cannot proceed.")
}
dat = data.frame( yi, vi, A, clustervar )
##### Fixed-Effects Model #####
if ( model == "fixed" ) {
# FE mean and sum of weights stratified by affirmative vs. nonaffirmative
strat = dat %>% group_by(A) %>%
summarise( nu = sum( 1 / vi ),
ybar = sum( yi / vi ) )
# components of bias-corrected estimate by affirmative status
ybarN = strat$ybar[ strat$A == 0 ]
ybarA = strat$ybar[ strat$A == 1 ]
nuN = strat$nu[ strat$A == 0 ]
nuA = strat$nu[ strat$A == 1 ]
# S-value for point estimate
sval.est = ( nuA * q - ybarA ) / ( ybarN - nuN * q )
# S-value for CI (to shift it to q)
# match term names used in Wolfram Alpha
a = ybarN
b = ybarA
c = nuN
d = nuA
if ( small == FALSE ) k = qnorm( 1 - (alpha/2) )
if ( small == TRUE ) {
df = k.studies - 1
k = qt( 1 - (alpha/2), df = df )
}
# # version directly from Wolfram
# termA = a^2 * d * k^2 - (2 * a * c * d * k^2 * q) +
#           b^2 * c * k^2 -
#           (2 * b * c * d * k^2 * q) +
#           c^2 * d * k^2 * q^2 +
#           c * d^2 * k^2 * q^2 -
#           c * d * k^4
# manually simplied version
termA = k^2 * ( a^2 * d -
(2 * c * d * q) * (a + b) +
b^2 * c +
q^2 * (c^2 * d + d^2 * c) -
c * d * k^2 )
termB = -a*b + a*d*q + b*c*q - c*d*q^2
termC = a^2 - 2*a*c*q + c^2*q^2 - c*k^2
sval.ci = ( -sqrt(termA) + termB ) / termC
if ( sval.ci < 0 ) sval.ci = ( sqrt(termA) + termB ) / termC
# # sanity check by inversion
# # corrected CI limit
# eta = sval.ci
# termD = (eta * a + b) / (eta * c + d)
# termE = k * sqrt( (eta^2 * c + d) / (eta * c + d)^2 )
# expect_equal( termD - termE,
#               q )
# # WORKS!!!
} # end fixed = TRUE
##### Robust Independent and Robust Clustered #####
if ( model == "robust" ) {
##### Worst-Case Meta to See if We Should Search at All
# first fit worst-case meta to see if we should even attempt grid search
# initialize a dumb (unclustered and uncorrected) version of tau^2
# which is only used for constructing weights
meta.re = rma.uni( yi = yi,
vi = vi)
t2hat.naive = meta.re$tau2
# fit model exactly as in corrected_meta
meta.worst =  robu( yi ~ 1,
studynum = clustervar,
data = dat[ A == FALSE, ],
userweights = 1 / (vi + t2hat.naive),
var.eff.size = vi,
small = small )
est.worst = as.numeric(meta.worst$b.r)
lo.worst = meta.worst$reg_table$CI.L
##### Get S-value for estimate
if ( est.worst > q ) {
sval.est = "Not possible"
} else {
# define the function we need to minimize
# i.e., distance between corrected estimate and the target value of q
func = function(.eta) {
est.corr = corrected_meta( yi = yi,
vi = vi,
eta = .eta,
model = model,
clustervar = clustervar,
selection.tails = 1,
favor.positive = TRUE,  # always TRUE because we've already flipped signs if needed
CI.level = CI.level,
small = small )$est
return( abs(est.corr - q))
}
opt = optimize( f = func,
interval = c(1, eta.grid.hi),
maximum = FALSE )
sval.est = opt$minimum
# discrepancy between the corrected estimate and the s-value
diff = opt$objective
# if the optimal value is very close to the upper range of grid search
#  AND we're still not very close to the target q,
#  that means the optimal value was above eta.grid.hi
if ( abs(sval.est - eta.grid.hi) < 0.0001 & diff > 0.0001 ) sval.est = paste(">", eta.grid.hi)
}
# do something similar for CI
if ( lo.worst > q ) {
sval.ci = "Not possible"
} else {
# define the function we need to minimize
# i.e., distance between corrected estimate and the target value of q
func = function(.eta) {
lo.corr = corrected_meta( yi = yi,
vi = vi,
eta = .eta,
model = model,
clustervar = clustervar,
selection.tails = 1,
favor.positive = TRUE, # always TRUE because we've already flipped signs if needed
CI.level = CI.level,
small = small )$lo
return( abs(lo.corr - q))
}
opt = optimize( f = func,
interval = c(1, eta.grid.hi),
maximum = FALSE )
sval.ci = opt$minimum
# discrepancy between the corrected estimate and the s-value
diff = opt$objective
# if the optimal value is very close to the upper range of grid search
#  AND we're still not very close to the target q,
#  that means the optimal value was above eta.grid.hi
if ( abs(sval.ci - eta.grid.hi) < 0.0001 & diff > 0.0001 ) sval.ci = paste(">", eta.grid.hi)
}
# ##### Worst-case bound #####
# # as eta -> infinity
# # not supposed to use KNHA for FE model
#
# # flip signs back to original direction if needed
# if ( flipped == TRUE ) {
#   yi = -yi
# }
#
# meta.bd = corrected_meta( yi = yi[ A == 0 ],
#                 vi = vi[ A == 0 ],
#                 eta = 1,
#                 model = model,
#                 CI.level = CI.level,
#                 small = small )
}
# s-values less than 1 indicate complete robustness
# is.numeric is in case we have a "< XXX" string instead of a number
if ( is.numeric(sval.est) & !is.na(sval.est) & sval.est < 1) sval.est = "Not possible"
if ( is.numeric(sval.ci) & !is.na(sval.ci) & sval.ci < 1) sval.ci = "Not possible"
return( data.frame( sval.est,
sval.ci = sval.ci,
k.affirmative,
k.nonaffirmative,
signs.recoded = flipped ) )
}
############################# FN: SIGNIFICANCE FUNNEL PLOT #############################
#' Make significance funnel plot
#'
svalue( yi = dat$yi,
vi = dat$vi,
q = 0,
favor.positive = FALSE,
model = "robust" )
svalue( yi = -dat$yi,
vi = dat$vi,
q = 0,
favor.positive = TRUE,
model = "robust" )
svalue( yi = -dat$yi,
vi = dat$vi,
q = log(.9),
favor.positive = TRUE,
model = "robust" )
svalue( yi = -dat$yi,
vi = dat$vi,
q = log(.9),
favor.positive = FALSE,
model = "robust" )
svalue( yi = dat$yi,
vi = dat$vi,
q = log(.9),
favor.positive = FALSE,
model = "robust" )
document()
check()
build()
build()
library(PublicationBias)
install.packages("PublicationBias")
library(PublicationBias)
?svalue
# calculate effect sizes from example dataset in metafor
require(metafor)
dat = metafor::escalc(measure="RR", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg)
head(Ddat)
head(dat)
dat$pval = 2 * ( 1 - pnorm( abs(dat$yi)/sqrt(dat$vi) ) )
table(dat$pval<.05)
mean(dat$yi)
d$nonaffirm  = dat$pval > 0.05 | dat$yi > 0
dat$nonaffirm  = dat$pval > 0.05 | dat$yi > 0
nonaffirms = which( dat$nonaffirm == 0)
( N = which( dat$nonaffirm == 0) )
length(N)
dat = dat[ -c(N[1:7]), ]
table(dat$nonaffirm)
##### Fixed-Effects Specification #####
# S-values and worst-case meta-analysis under fixed-effects specification
svals.FE.0 = svalue( yi = dat$yi,
vi = dat$vi,
q = 0,
favor.positive = FALSE,
model = "fixed" )
# publication bias required to shift point estimate to 0
svals.FE.0$sval.est
##### Robust Clustered Specification #####
svalue( yi = dat$yi,
vi = dat$vi,
q = 0,
favor.positive = FALSE,
model = "robust" )
table(dat$nonaffirm)
# calculate effect sizes from example dataset in metafor
require(metafor)
dat = metafor::escalc(measure="RR", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg)
dat$pval = 2 * ( 1 - pnorm( abs(dat$yi)/sqrt(dat$vi) ) )
# here the point estimate is negative, so nonaffirmatives could have positive estimates
dat$nonaffirm  = dat$pval > 0.05 | dat$yi > 0
# keep only 1 nonaffirmative study
( N = which( dat$nonaffirm == 0) )
dat = dat[ -c(N[1:7]), ]
table(dat$nonaffirm)
##### Robust Clustered Specification #####
svalue( yi = dat$yi,
vi = dat$vi,
q = 0,
favor.positive = FALSE,
model = "robust" )
require(metafor)
dat = metafor::escalc(measure="RR", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg)
dat$pval = 2 * ( 1 - pnorm( abs(dat$yi)/sqrt(dat$vi) ) )
# here the point estimate is negative, so nonaffirmatives could have positive estimates
dat$nonaffirm  = dat$pval > 0.05 | dat$yi > 0
--------------------------------------------
# keep only 1 nonaffirmative study
( N = which( dat$nonaffirm == 0) )
dat = dat[ -c(N[1:7]), ]
table(dat$nonaffirm)
--------------------------------------------
--------------------------------------------
# keep only 1 nonaffirmative study
( N = which( dat$nonaffirm == 1) )
dat = dat[ -c(N[1:4]), ]
table(dat$nonaffirm)
--------------------------------------------
library(PublicationBias)
# calculate effect sizes from example dataset in metafor
require(metafor)
dat = metafor::escalc(measure="RR", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg)
dat$pval = 2 * ( 1 - pnorm( abs(dat$yi)/sqrt(dat$vi) ) )
# here the point estimate is negative, so nonaffirmatives could have positive estimates
dat$nonaffirm  = dat$pval > 0.05 | dat$yi > 0
# keep only 1 nonaffirmative study
( N = which( dat$nonaffirm == 0) )
# keep only 1 nonaffirmative study
( N = which( dat$nonaffirm == 1) )
dat = dat[ -c(1,5,8,12), ]
table(dat$nonaffirm)
##### Robust Clustered Specification #####
svalue( yi = dat$yi,
vi = dat$vi,
q = 0,
favor.positive = FALSE,
model = "robust" )
source('~/Dropbox/Personal computer/Independent studies/Sensitivity analysis for publication bias (SAPB)/Linked to OSF (SAPB)/R package PublicationBias/PublicationBias/R/functions.R')
source('~/Dropbox/Personal computer/Independent studies/Sensitivity analysis for publication bias (SAPB)/Linked to OSF (SAPB)/R package PublicationBias/PublicationBias/R/functions.R')
##### Robust Clustered Specification #####
svalue( yi = dat$yi,
vi = dat$vi,
q = 0,
favor.positive = FALSE,
model = "robust" )
library(robumeta)
##### Robust Clustered Specification #####
svalue( yi = dat$yi,
vi = dat$vi,
q = 0,
favor.positive = FALSE,
model = "robust" )
m0
A
k.nonaffirmative
meta.re
source('~/Dropbox/Personal computer/Independent studies/Sensitivity analysis for publication bias (SAPB)/Linked to OSF (SAPB)/R package PublicationBias/PublicationBias/R/functions.R')
##### Robust Clustered Specification #####
svalue( yi = dat$yi,
vi = dat$vi,
q = 0,
favor.positive = FALSE,
model = "robust" )
head(dat)
dat$yi[ A == FALSE ]
lo.worst = dat$yi[ A == FALSE ] - qnorm(0.975)* sqrt(dat$vi[ A == FALSE ])
sval.est
eval.ci
sval.ci
source('~/Dropbox/Personal computer/Independent studies/Sensitivity analysis for publication bias (SAPB)/Linked to OSF (SAPB)/R package PublicationBias/PublicationBias/R/functions.R')
##### Robust Clustered Specification #####
svalue( yi = dat$yi,
vi = dat$vi,
q = 0,
favor.positive = FALSE,
model = "robust" )
setwd("~/Desktop/reupdateshrtumbrellareview")
library(readxl)
library(MetaUtility)
library(dplyr)
library(PublicationBias)
setwd(data.dir)
head(rawdata1)
rawdata1 <- read_excel( "Gallbladder Disease.xlsx", skip = 47 )
# remove any blank rows at the end
rawdata2 <- rawdata1[ !is.na(rawdata1$NumberOfCases), ]
# drop variables not needed for analysis
d <- rawdata2 %>% select( AuthorOfPaper, YearOfPublication, StudyDesign, HRTDefinition, Outcome, NumberOfCases, NumberOfPopulation, TypeOfEffectEstimate, PointEstimate, `Lower95%CI`, `Upper95%CI` )
# because outcome is rare, HR/OR approximate RR
d$logRR <- log( as.numeric(d$PointEstimate) )
d$varlogRR <- MetaUtility::scrape_meta( type = "RR",
est = as.numeric(d$PointEstimate),
hi = as.numeric(d$`Upper95%CI`) )$vyi
head(rawdata1)
d$pval <- 2 * ( 1 - pnorm( abs(d$logRR)/sqrt(d$varlogRR) ) )
# the pooled estimate is positive
d$nonaffirm <- d$pval >= 0.05 | d$logRR < 0
table(d$nonaffirm) # there are 8 affirmative studies and 1 nonaffirmative study
svalue( yi = d$logRR, vi = d$varlogRR, q = log(1.0), model = "robust", favor.positive = TRUE, small = TRUE )
svalue( yi = d$logRR, vi = d$varlogRR, q = log(1.1), model = "robust", favor.positive = TRUE, small = TRUE )
svalue( yi = d$logRR, vi = d$varlogRR, q = log(1.0), model = "robust", favor.positive = TRUE, small = TRUE )
svalue( yi = d$logRR, vi = d$varlogRR, q = log(1.1), model = "robust", favor.positive = TRUE, small = TRUE )
svalue( yi = d$logRR, vi = d$varlogRR, q = log(1.0), model = "fixed", favor.positive = TRUE, small = TRUE )
svalue( yi = d$logRR, vi = d$varlogRR, q = log(1.0), model = "fixed", favor.positive = TRUE, small = TRUE )
library(devtools)
check()
setwd("~/Dropbox/Personal computer/Independent studies/Sensitivity analysis for publication bias (SAPB)/Linked to OSF (SAPB)/R package PublicationBias/PublicationBias")
check()
build()
