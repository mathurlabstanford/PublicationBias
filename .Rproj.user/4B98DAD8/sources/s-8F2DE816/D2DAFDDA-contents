
# Question: Can we fix the Vevea/Woods correct_est_re_score by directly weighting the score
#  contributions per Wooldridge's IPW work?

rm(list=ls())


setwd("~/Dropbox/Personal computer/Independent studies/Sensitivity analysis for publication bias (SAPB)/Applied examples/Shared code")
source("helper_sapb.R")
source("weightfunct from package.R")
source("bootfuns.R")  # internal fns from boot package called by my_boot

eta = 3
mu = .17
V = 0.05^2
p = data.frame( mu = mu,
                k = 500,
                #sei.min = min(d$sei),
                #sei.max = max(d$sei),
                sei.min = 0.1,
                sei.max = 0.3,
                V = V,
                V.gam = 0, 
                per.cluster = 1,
                eta = eta )

ds = sim_data(p)

# regular meta-analysis on all studies
library(metafor)
( meta.rma = rma.uni( yi = ds$yi,
                      vi = ds$vi,
                      method = "REML" ) )

# regular meta-analysis on only NS studies
library(metafor)
( meta.NS = rma.uni( yi = ds$yi[ds$weight > 1],
                     vi = ds$vi[ds$weight > 1],
                     method = "REML" ) )
# this should be an approximate lower bound as eta -> infty (0.0989)



##### Sanity Check: should evaluate to 0 at real MLEs #####

( real.mle.meta = rma.uni( yi = ds$yi,
                     vi = ds$vi,
                     method = "ML" ) )

my.weights = rep(1, nrow(ds))
( real.mles = c(real.mle.meta$b, real.mle.meta$tau2 ) )
( real.mle.se = c( sqrt(real.mle.meta$vb), real.mle.meta$se.tau2 ) )

get_score( real.mles, weights = my.weights )  # should be almost 0

# find unweighted MLEs 
my.weights = rep(1, nrow(ds))
library(nleqslv)
solns = nleqslv(x = c(0, 0),
                fn = get_score,
                method = "Newton",
               #jac = Jac,
               jacobian = TRUE,
                global = "cline" )
( my.ests = solns$x )
solns$message
J.emp = solns$jac

# YES!! EXACTLY THE SAME :D
my.ests; real.mles

# compare inference
my.jac = J.emp
mle.var = -1/J.emp  # not inverting matrix, but rather 1/each entry
( mle.se = sqrt(mle.var) ); real.mle.se
# correct! :D

# with inversion
sqrt( solve(-J.emp) )
# similar

my.jac = Jac( my.ests )
mle.var = -1/my.jac  # not inverting matrix, but rather 1/each entry
( mle.se = sqrt(mle.var) )
# my tau^2 part of Jacobian is wrong


######################### TRY WITH WEIGHTING (CORRECT ETA) ######################### 

# SEEMS LIKE IT'S WORKING! KEY SEEMS TO BE STARTING TAU^2 AT 0 SO THAT IT 
#  DOESN'T BLOW UP. 
my.weights = ds$weight
my.weights[ my.weights > 1 ] =1

library(nleqslv)
solns = nleqslv(x = c(0, 0),
                fn = correct_est_re_score,
                method = "Newton",
                jacobian = TRUE,
                global = "cline" )
( my.ests = solns$x )
J.emp = solns$jac
solns$message

# inference
# Wooldridge pg 13
ki = correct_est_re_score( my.ests, 
            individ.terms = TRUE )
B0 = t(ki) %*% ki   # NOT SURE ABOUT THIS
var = solve(-J.emp) %*% B0 %*% solve(-J.emp)
( se = sqrt(var) )



# sqrt(solve(-J.emp))
# sqrt(-1/J.emp)

# compare to rma.uni
# makes sense when eta = 1
se; real.mle.se  # pretty close

# compare to weightfunct
# makes sense when wrong.eta matches true eta
library(weightr)
( meta.wf = weightfunct_mm( effect = ds$yi,
                         v = ds$vi,
                         weights = c(1, 1/max(ds$weight)) ) )
sqrt( 1 / meta.wf$output_adj$hessian[1:2,1:2] )
# hmmm...mine are different when setting eta to the truth.
# they are closer to rma.uni's


######################### TRY WITH REAL PALUCK DATA ######################### 

# figure out the following:
# eta = 100 vs. 150 INCREASES the point estimate
# eta = 50 and nearby has NA

setwd("~/Dropbox/Personal computer/Independent studies/Sensitivity analysis for publication bias (SAPB)/Applied examples/Data/Paluck data")
d = read.csv("paluck_prepped.csv")

setwd("~/Dropbox/Personal computer/Independent studies/Sensitivity analysis for publication bias (SAPB)/Applied examples/Shared code")
source("helper_SAPB.R")


my.eta = 55  # this is a good one to look at
#my.eta = 7
weights = rep(1, nrow(d))
weights[ d$pval > 0.05 | d$yi < 0 ] = my.eta
table(weights)

correct_est_re_score( yi = d$yi, 
                              v = d$vi,
                              weights = weights,
                              start.ests = c(0,0) )

# NAs are because it hit the "no better point found" error

# compare to meta-analyzing only the NS ones
library(metafor)
rma.uni( yi = d$yi[ weights > 1 ],
         vi = d$vi[ weights > 1 ],
         method = "ML" )



##### BOOKMARK #####
# compare empirical Jacobian to mine

library(nleqslv)
solns = nleqslv(x = c(0,0),
                fn = function(x) get_score( x = x, 
                                            yi = d$yi, 
                                            vi = d$vi, 
                                            weights = weights ),
                method = "Newton",
                jacobian = TRUE,
                global = "cline" )
( my.ests = solns$x )
( J.emp = solns$jac )

# mine
# when all weights 1, matches 
Jac( x = my.ests, 
     yi = d$yi,
     vi = d$vi,
     weights = weights )


# try using my Jacobian
solns = nleqslv(x = c(5,5),
                fn = function(x) get_score( x = x, 
                                            yi = d$yi, 
                                            vi = d$vi, 
                                            weights = weights ),
                method = "Newton",
                jac = function(x) Jac( x, 
                                       yi = d$yi, 
                                       vi = d$vi,
                                       weights = weights ),
                jacobian = TRUE, 
                global = "cline" )
solns$x

rma.uni(  yi = d$yi, 
          vi = d$vi,
          method = "ML" )

# CONCLUSION: PASSING MY OWN JACOBIAN DOESN'T HELP


